{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering News\n",
    "### This dataset has been downloaded from https://www.kaggle.com/rmisra/news-category-dataset.\n",
    "### Our goal is to categorize news articles based on their headlines and short descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "#confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "news = pd.read_csv('/media/sf_FormacaoCientistaDeDados/Portfolio/News_Category/news-category-dataset/news_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>South Korean President Meets North Korea's Kim...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/south-kor...</td>\n",
       "      <td>The two met to pave the way for a summit betwe...</td>\n",
       "      <td>South Korean President Meets North Korea's Kim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>David Moye</td>\n",
       "      <td>WEIRD NEWS</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Weird Father's Day Gifts Your Dad Doesn't Know...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/weird-fat...</td>\n",
       "      <td>Why buy a boring tie when you can give him tes...</td>\n",
       "      <td>Weird Father's Day Gifts Your Dad Doesn't Know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hilary Hanson</td>\n",
       "      <td>WEIRD NEWS</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Mystery 'Wolf-Like' Animal Reportedly Shot In ...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/montana-w...</td>\n",
       "      <td>“We have no idea what this was until we get a ...</td>\n",
       "      <td>Mystery 'Wolf-Like' Animal Reportedly Shot In ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Josh Smith and Christine Kim, Reuters</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>North Korea Still Open To Talks After Trump Ca...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/north-kor...</td>\n",
       "      <td>Trump’s announcement came after repeated threa...</td>\n",
       "      <td>North Korea Still Open To Talks After Trump Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>2 Men Detonate Bomb Inside Indian Restaurant N...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/mississau...</td>\n",
       "      <td>Fifteen people were taken to the hospital, thr...</td>\n",
       "      <td>2 Men Detonate Bomb Inside Indian Restaurant N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                authors    category        date  \\\n",
       "0           0                                    NaN  WORLD NEWS  2018-05-26   \n",
       "1           1                             David Moye  WEIRD NEWS  2018-05-26   \n",
       "2           2                          Hilary Hanson  WEIRD NEWS  2018-05-26   \n",
       "3           3  Josh Smith and Christine Kim, Reuters  WORLD NEWS  2018-05-25   \n",
       "4           4                                    NaN  WORLD NEWS  2018-05-25   \n",
       "\n",
       "                                            headline  \\\n",
       "0  South Korean President Meets North Korea's Kim...   \n",
       "1  Weird Father's Day Gifts Your Dad Doesn't Know...   \n",
       "2  Mystery 'Wolf-Like' Animal Reportedly Shot In ...   \n",
       "3  North Korea Still Open To Talks After Trump Ca...   \n",
       "4  2 Men Detonate Bomb Inside Indian Restaurant N...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.huffingtonpost.com/entry/south-kor...   \n",
       "1  https://www.huffingtonpost.com/entry/weird-fat...   \n",
       "2  https://www.huffingtonpost.com/entry/montana-w...   \n",
       "3  https://www.huffingtonpost.com/entry/north-kor...   \n",
       "4  https://www.huffingtonpost.com/entry/mississau...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  The two met to pave the way for a summit betwe...   \n",
       "1  Why buy a boring tie when you can give him tes...   \n",
       "2  “We have no idea what this was until we get a ...   \n",
       "3  Trump’s announcement came after repeated threa...   \n",
       "4  Fifteen people were taken to the hospital, thr...   \n",
       "\n",
       "                                                text  \n",
       "0  South Korean President Meets North Korea's Kim...  \n",
       "1  Weird Father's Day Gifts Your Dad Doesn't Know...  \n",
       "2  Mystery 'Wolf-Like' Animal Reportedly Shot In ...  \n",
       "3  North Korea Still Open To Talks After Trump Ca...  \n",
       "4  2 Men Detonate Bomb Inside Indian Restaurant N...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 rows\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this model, we've using only \"category\" and \"text\" columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns\n",
    "news.drop(columns=['authors','date','headline','link','short_description','Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21450 entries, 0 to 21449\n",
      "Data columns (total 2 columns):\n",
      "category    21450 non-null object\n",
      "text        21450 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 335.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking missing values, columns and rowcount\n",
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GREEN</th>\n",
       "      <td>2622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDIA</th>\n",
       "      <td>2815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RELIGION</th>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCIENCE</th>\n",
       "      <td>2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STYLE</th>\n",
       "      <td>2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TASTE</th>\n",
       "      <td>2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECH</th>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEIRD NEWS</th>\n",
       "      <td>2670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORLD NEWS</th>\n",
       "      <td>2177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text\n",
       "category        \n",
       "GREEN       2622\n",
       "MEDIA       2815\n",
       "RELIGION    2556\n",
       "SCIENCE     2178\n",
       "STYLE       2254\n",
       "TASTE       2096\n",
       "TECH        2082\n",
       "WEIRD NEWS  2670\n",
       "WORLD NEWS  2177"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouping text by category\n",
    "news.groupby(['category']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21450, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the dataset\n",
    "news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "#### We'll to turn \"text\" feature into word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing\n",
    "def preprocessing(text):\n",
    "    #removing the punctuation\n",
    "    text_v2 = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in text]).split())\n",
    "    #tokenizes sentences into words\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text_v2) for word in nltk.word_tokenize(sent)]\n",
    "    #lowercase\n",
    "    tokens =[word.lower() for word in tokens]\n",
    "    #Removing stopwords\n",
    "    stopwds = stopwords.words('english')\n",
    "    tokens = [token for token in tokens if token not in stopwds]\n",
    "    #Removing words lenght <  3\n",
    "    tokens = [token for token in tokens if len(tokens) >=3 ]\n",
    "    #Stemming (\"eating\" into \"eat\")\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    #POS tagging ( tags to words , ex running is verb)\n",
    "    tagged_corpus = pos_tag(tokens)\n",
    "    \n",
    "    Noun_tags = ['NN','NNP','NNPS','NNS']\n",
    "    Verb_tags = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "    #lemmatizer (brings down word to root word, ex ate into eat, but considering tagging)\n",
    "    #Source: https://en.wikipedia.org/wiki/Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def prat_lemmatize(token,tag):\n",
    "        if tag in Noun_tags:\n",
    "            return lemmatizer.lemmatize(token,'n')\n",
    "        elif tag in Verb_tags:\n",
    "            return lemmatizer.lemmatize(token,'v')\n",
    "        else:\n",
    "            return lemmatizer.lemmatize(token,'n')\n",
    "    \n",
    "    \n",
    "    pre_proc_text = ' '.join([prat_lemmatize(token,tag)for token ,tag in tagged_corpus])\n",
    "    \n",
    "    return pre_proc_text\n",
    "\n",
    "\n",
    "# References: Statistics for Machine Learning,2017, p 212 ,author Pratap Dangeti\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the preprocessing function\n",
    "news_normalized = []\n",
    "for r in news['text']:\n",
    "    news_normalized.append(preprocessing(r))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(news_normalized, news['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building TFIDF Vectorizer\n",
    "# min_df = ignore terms lower than the given threshould \n",
    "# strip_accents = remove accents and perform other normalization\n",
    "# ngram_range = sets of consecutive words ex\n",
    "vectorizer = TfidfVectorizer(min_df=3 ,stop_words ='english',strip_accents='unicode',ngram_range=(1,2))#,norm='l1')\n",
    "x_train_2 = vectorizer.fit_transform(x_train).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "nb = MultinomialNB().fit(x_train_2,y_train)\n",
    "#Predict\n",
    "nb_predicted = nb.predict(x_train_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test dataset \n",
    "x_test_2 = vectorizer.transform(x_test).todense() \n",
    "nb_predicted_test = nb.predict(x_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>MEDIA</th>\n",
       "      <th>RELIGION</th>\n",
       "      <th>SCIENCE</th>\n",
       "      <th>STYLE</th>\n",
       "      <th>TASTE</th>\n",
       "      <th>TECH</th>\n",
       "      <th>WEIRD NEWS</th>\n",
       "      <th>WORLD NEWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actuall</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GREEN</th>\n",
       "      <td>539</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDIA</th>\n",
       "      <td>14</td>\n",
       "      <td>627</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RELIGION</th>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>530</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCIENCE</th>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>370</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STYLE</th>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>443</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TASTE</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>416</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECH</th>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>371</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEIRD NEWS</th>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>441</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORLD NEWS</th>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   GREEN  MEDIA  RELIGION  SCIENCE  STYLE  TASTE  TECH  WEIRD NEWS  \\\n",
       "Actuall                                                                       \n",
       "GREEN         539     15         7       20      5     15     2          71   \n",
       "MEDIA          14    627        22        5      2      2    24          18   \n",
       "RELIGION       20     28       530       10      4      6     4          15   \n",
       "SCIENCE        65     14        25      370     11      8    10          29   \n",
       "STYLE          15     27        13        8    443     16     8          41   \n",
       "TASTE          15     12         9        7     15    416     9          27   \n",
       "TECH           16     39        11       12     11      4   371          28   \n",
       "WEIRD NEWS     42     37        19       22     16     28    13         441   \n",
       "WORLD NEWS     54     32        56        5      2      0    10          19   \n",
       "\n",
       "Predicted   WORLD NEWS  \n",
       "Actuall                 \n",
       "GREEN                9  \n",
       "MEDIA               14  \n",
       "RELIGION            14  \n",
       "SCIENCE              0  \n",
       "STYLE                3  \n",
       "TASTE                1  \n",
       "TECH                 7  \n",
       "WEIRD NEWS           6  \n",
       "WORLD NEWS         403  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion_matrix \n",
    "pd.crosstab(y_test, nb_predicted_test,rownames =[\"Actuall\"],colnames = [\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      GREEN       0.69      0.79      0.74       683\n",
      "      MEDIA       0.75      0.86      0.80       728\n",
      "   RELIGION       0.77      0.84      0.80       631\n",
      "    SCIENCE       0.81      0.70      0.75       532\n",
      "      STYLE       0.87      0.77      0.82       574\n",
      "      TASTE       0.84      0.81      0.83       511\n",
      "       TECH       0.82      0.74      0.78       499\n",
      " WEIRD NEWS       0.64      0.71      0.67       624\n",
      " WORLD NEWS       0.88      0.69      0.78       581\n",
      "\n",
      "avg / total       0.78      0.77      0.77      5363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# score on test dataset\n",
    "print(classification_report(y_test, nb_predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ed2bfa928f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# K-means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialization complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     centers, labels, n_iter = k_means_elkan(X, n_clusters, centers, tol=tol,\n\u001b[0;32m--> 400\u001b[0;31m                                             max_iter=max_iter, verbose=verbose)\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0minertia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/cluster/_k_means_elkan.pyx\u001b[0m in \u001b[0;36msklearn.cluster._k_means_elkan.k_means_elkan\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-means\n",
    "km = KMeans(n_clusters = 9,init= 'random',n_init=1,verbose = 1)\n",
    "km.fit(x_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7243,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.10199847e-04,   2.55529676e-03,   1.67927139e-04, ...,\n",
       "          2.41521866e-04,   9.00642152e-04,   5.82826854e-05],\n",
       "       [ -5.14996032e-19,   1.64798730e-17,   1.62630326e-19, ...,\n",
       "         -5.96311195e-19,   1.57353824e-03,  -8.13151629e-19],\n",
       "       [  2.98155597e-19,  -2.16840434e-18,   0.00000000e+00, ...,\n",
       "         -4.33680869e-19,  -8.67361738e-19,   1.35525272e-19],\n",
       "       [  2.39945655e-04,   4.27605676e-03,   7.42743450e-04, ...,\n",
       "          9.67587611e-04,   3.03043404e-04,   5.94420561e-04]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Centroids\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0    1   2    3\n",
      "Actuall                       \n",
      "RELIGION    1650   38  99  115\n",
      "SCIENCE      801   56   0  759\n",
      "STYLE       1341  235   0  127\n",
      "WEIRD NEWS  1830   69   0  123\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(pd.crosstab(y_train, km.labels_,rownames = [\"Actuall\"],colnames = [\"Predicted\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
